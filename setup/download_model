import os
import sys
from pathlib import Path

from huggingface_hub import login, snapshot_download, scan_cache_dir
from huggingface_hub.errors import HfHubHTTPError


def main():
    # ============================
    # CONFIGURATION
    # ============================
    # Preferred: set HF_TOKEN as an environment variable before running:
    #   export HF_TOKEN=hf_...
    #
    # Alternatively, you can hardcode the token here (not recommended for Git):
    HF_TOKEN = os.environ.get("HF_TOKEN", "")

    if not HF_TOKEN:
        print(
            "[ERROR] No token found.\n"
            " - Set the HF_TOKEN environment variable with your token, or\n"
            " - edit this file and assign the token directly to HF_TOKEN.\n"
        )
        sys.exit(1)

    MODEL_ID = "meta-llama/Meta-Llama-3-8B"

    cache_info = scan_cache_dir()
    model_ids = [
        (repo.repo_id, repo.repo_path)
        for repo in cache_info.repos
        if repo.repo_id == MODEL_ID
    ][0]

    model_id = model_ids[0]
    model_path = model_ids[1]

    # Directory where the model is stored (from local cache)
    MODEL_DIR = Path(model_path)

    print("============================================")
    print("  LOGIN TO HUGGING FACE")
    print("============================================")

    try:
        login(token=HF_TOKEN, add_to_git_credential=True)
        print("[OK] Login completed.\n")
    except Exception as e:
        print("[ERROR] Login failed:", e)
        sys.exit(1)

    # Check if the model is already present (tokenizer.model as an indicator)
    tokenizer_path = MODEL_DIR / "tokenizer.model"
    if tokenizer_path.exists():
        print(f"[INFO] Model already present in: {MODEL_DIR}")
        print(f"       (found: {tokenizer_path.name})\n")
    else:
        print("============================================")
        print(f"  DOWNLOAD MODEL: {MODEL_ID}")
        print("============================================")
        print(f"Downloading into folder: {MODEL_DIR}\n")

        try:
            snapshot_download(
                repo_id=MODEL_ID,
                local_dir=str(MODEL_DIR),
                local_dir_use_symlinks=False,
                token=HF_TOKEN,
            )
            print("\n[OK] Download completed.")
        except HfHubHTTPError as e:
            print("[ERROR] HTTP problem during download:")
            print(" ", e)
            print("\nPossible causes:")
            print(" - You have not accepted the model terms on Hugging Face.")
            print(" - The token does not have permission to access the repo.")
            sys.exit(1)
        except Exception as e:
            print("[ERROR] Download failed:", e)
            sys.exit(1)

    # Final check
    print("\n============================================")
    print("  CHECK REQUIRED FILES")
    print("============================================")

    missing = []
    for fname in ["tokenizer.model", "config.json", "tokenizer_config.json"]:
        if not (MODEL_DIR / fname).exists():
            missing.append(fname)

    if missing:
        print("[WARNING] Some files were not found:")
        for m in missing:
            print(" -", m)
        print("The model may still work, but please check the folder.")
    else:
        print("[OK] Main files found (tokenizer + config).")

    print("[END] Setup completed.")


if __name__ == "__main__":
    main()
